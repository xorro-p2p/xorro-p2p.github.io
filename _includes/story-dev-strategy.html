<h2>Development Strategy: Simulating and Scaling a Network Application From a Local Environment to a Real Network</h2>
  <h3>Phase 1: Test Mode</h3>

  <p>So.. how did we go about building and testing this?</p>
  <p>
    In the early stages of our project, we needed to test inter-node communications, but all we had were our classes and test suites, there was no network, no RPC transport, not even multiple computers.
  </p>
  <p>
    We could have had one node call methods directly on another node object, but this would have broken down quickly once a true network environment was introduced and those objects weren’t directly available.
  </p>
  <p>
     We needed some sort of proxy object that would function one way during testing and local development, and another way when deployed onto a real network environment.
  </p>
  
  <p>Our solution was to have individual nodes delegate all network communications to a pre-existing Network Adapter object.</p>

  <p>When testing, this Network Adapter would actually be a ‘Fake Network Adapter’ -- essentially an array of other nodes, with some methods for lookup and RPC proxy. This allowed us to test our node interactions in a local sandbox without an RPC transport protocol.</p>

  <p>The typical workflow would look something like the diagram below.<p>
  <img src="public/images/strategy1.png" alt="">
  
  <ul>
    <li>Node A asks the network to deliver an RPC to Node B, Node A provides the contact info - IP, IP and Port.</li>
    <li>Network looks up if Node B exists. -- in Fake network environment this is done by ID from contact.</li>
    <li>Network directly calls method on Node B, which changes state and/or returns some data in response.</li>
    <li>Network delivers that response back to Node A, which in turn changes state or reacts to this new information</li>
  </ul>
    
  <h3>Phase 2: RPC via HTTP in a Local Sandbox</h3>
  <p>Our next step was to introduce HTTP as the underlying protocol upon which we built our RPC methods.</p>
  <p>To do this, we implemented a Real Network Adapter object. It has the same interface as our Fake Network Adapter, but instead of looking up the recipient node by ID and calling the method directly, the Real Network Adapter crafts an HTTP Post request from the IP/Port listed in the contact info provided, and the route corresponding to the RPC call, possibly including relevant data in the request body -- contact info of the requester, query info, etc.<p>


  <p>The typical workflow is similar to the previous slide:</p>
  <img src="public/images/strategy2.png" alt="">
  <ul>
    <li>Node A asks the network to deliver an RPC to Node B, Node A provides the contact info - IP, IP and Port.</li>
    <li>Network crafts an HTTP POST request for the IP, PORT, and RPC path, and sends it along with any payload data</li>
    <li>HTTP endpoint of recipient node receives POST request, and it calls the receive rpc method on the Node object</li>
    <li>The return value of this recieve RPC method is converted to an HTTP response by the HTTP endpoint, and sent back to the network adapter of the calling Node</li>
    <li>The Network receives the response, and delivers it to Node A, which in turn changes state or reacts to this new information.</li>
  </ul>
  <p>As you can see, from the perspective of the Nodes, nothing has changed, each of them send and receive the same information, but the Network Object and HTTP endpoints abstract away the internode communications.</p>

  <h3>Phase 3: RPC/HTTP Over the Internet</h3>

  <img src="public/images/strategy3.png" alt="">
  <p>Once we knew that internode communications were working using HTTP in a local environment, or on a LAN, our next step was to deploy onto multiple systems across the internet. This worked fine if the systems were directly on the public internet, or if they were behind firewalls configured with ports already opened up.</p>

  <p>Nodes behind a NAT firewall were another story.  They could join the network fine and retrieve files fine, but without port forwarding, they cannot accept incoming http connections, and thus cannot contribute to the network.</p>

  <p>Long term, a TCP based RPC transport is the goal, as well as support for STUN and TURN servers to handle public IP/port discovery and incoming connections, however, in the scope of this project, we needed a quick way to work around NAT and Firewalls.</p>

  <p>To do this, we built support for Ngrok, a 3rd party tunneling service, so that nodes behind firewalls could be full functioning members of our network.</p>

  <h3>Flexible Node Instantiation and Launch Scripts</h3>

  <p>At this point we realized there were a number of different node configurations/environments that we needed to be able to support and test.  Furthermore we needed a way to move between these configurations quicky and seamlessly</p>

  <p>In each environment, a node broadcasts its IP/port, and the full url/path to each shard or manifest it hosts.</p>
  <ul>
    <li>If a node is directly on the internet, it should broadcast its own public IP port.</li>
    <li>If a node a node has a fully qualified domain name, the node should broadcast that instead of a numeric IP address.</li>
    <li>If a node is behind a firewall that is configured properly for NAT translation/and port forwarding, it can still rely on its public IP and port.</li>
    <li>If a node is behind a firewall that does not have ports forwarded, it needs to either:
      <ul>
        <li>
          Establish a tunnel to Ngrok’s servers, and be aware of its unique Ngrok address so it can advertise this to other nodes,
        </li>
        <li>
          Know that it is a "Leech" node, and not broadcast location info about any files that it hosts.
        </li>
      </ul>
  </ul>

  <p>We identified a number of configuration variables that a node might have, and created environtment variables to represent these options.  Our node instantiation code reacts to these environment variables, and we crafted a series of BASH scripts to standardize these configurations for each environment we were working in: test, local, lan, WAN, etc.</p>

  <img src="public/images/launch_scripts.png" alt="">

  <h3>System Architecture</h3>
  <p>Our final system architecture looks like this:</p>
  <img src="public/images/system_arch.png" alt="">
  <p>The top level object is XorroNode, which is a modular Sinatra application</p>
  <p>Each XorroNode contains:</p>
  <ul>
    <li>
      a single Kademlia Node, responsible for maintaining its own routing table and DHT
    </li>
    <li>A network adapter for initiating RPC calls to other nodes.</li>
    <li>A Sinatra endpoint for receiving RPC from other nodes, web UI, and file transport.</li>
    <li>File Utilities for file ingest, sharding, and manifest creation.</li>
  </ul>