<h2 id='dev_strategy'>Development Strategy: Simulating and Scaling a Network Application From a Local Environment to a Real Network</h2>
  <h3>Phase 1: Test Mode</h3>

  <p>So.. how did we go about building and testing this?</p>
  <p>
    In the early stages of our project, we needed to test inter-node communications, but all we had were our classes and test suites, there was no network, no RPC transport, not even multiple computers.
  </p>
  <p>
    It was fairly common for us to fire up Ruby's interactive shell (IRB), instantiate a few nodes, and get them communicating manually.  Of course this could be scripted, but it breaks down quickly once a true network environment is introduced and node objects aren't directly available in the same Ruby process.
  </p>
  <p>
     We needed some sort of proxy object that would function one way during testing and local development, and another way when deployed in a real network environment.
  </p>
  
  <p>Our solution was to have each node delegate all network communications to a pre-existing Network Adapter object.</p>

  <p>When testing, this Network Adapter would actually be a ‘Fake Network Adapter’ &mdash; essentially an array of other nodes, with some methods for lookup and RPC proxy. This allowed us to test our node interactions in a local sandbox without an RPC transport protocol.</p>

  <p>The typical workflow would look something like the diagram below.<p>
  <img src="public/images/strategy1.png" alt="">
  
  <ul>
    <li>Node A asks the network to deliver an RPC to Node B, Node A provides the contact info - ID, IP and Port.</li>
    <li>Network looks up if Node B exists &mdash; in Fake Network environment this is done by ID from contact.</li>
    <li>Network directly calls method on Node B, which changes state and/or returns some data in response.</li>
    <li>Network delivers that response back to Node A, which in turn changes state or reacts to this new information.</li>
  </ul>
    
  <h3>Phase 2: RPC via HTTP in a Local Sandbox</h3>
  <p>Our next step was to introduce HTTP as the underlying protocol upon which we built our RPC methods.</p>
  <p>To do this, we implemented a Real Network Adapter object. It has the same interface as our Fake Network Adapter, but instead of looking up the recipient node by ID and calling the method directly, the Real Network Adapter crafts an HTTP Post request from the IP/Port listed in the contact info provided and the route corresponding to the RPC call, possibly including relevant data in the request body &mdash; contact info of the requester, query info, etc.<p>


  <p>The typical workflow is similar to the previous slide:</p>
  <img src="public/images/strategy2.png" alt="">
  <ul>
    <li>Node A asks the network to deliver an RPC to Node B, Node A provides the contact info - ID, IP and Port.</li>
    <li>Network crafts an HTTP POST request for the IP, PORT, and RPC path, and sends it along with any payload data.</li>
    <li>HTTP endpoint of recipient node receives POST request, and it calls the receive RPC method on the Node object.</li>
    <li>The return value of this receive RPC method is converted to an HTTP response by the HTTP endpoint, and sent back to the network adapter of the calling Node.</li>
    <li>The Network receives the response, and delivers it to Node A, which in turn changes state or reacts to this new information.</li>
  </ul>
  <p>As you can see, from the perspective of the Nodes, nothing has changed &mdash; each of them send and receive the same information, but the Network Object and HTTP endpoints abstract away the internode communications.</p>

  <h3>Phase 3: RPC/HTTP Over the Internet</h3>

  <img src="public/images/strategy3.png" alt="">
  <p>Once we knew that internode communications were working using HTTP, our next step was to deploy nodes onto multiple systems across the internet. This worked fine if the systems were directly on the public internet, or if they were behind firewalls configured with ports already opened up.</p>

  <p>Nodes behind a NAT firewall were another story.  They could join the network fine and retrieve files fine, but without port forwarding, they cannot accept incoming http connections, and thus cannot contribute to the network.</p>

  <p>Long term, a TCP/UDP based RPC and file transport protocol is the goal, as well as support for STUN and TURN servers to handle public IP/port discovery and incoming connections. However, in the scope of this project we needed a quick way to work around NAT and Firewalls.</p>

  <p>To do this, we built support for Ngrok, a 3rd party tunneling service, so that nodes behind firewalls could be full functioning members of our network.</p>

  <h3>Flexible Node Instantiation and Launch Scripts</h3>

  <p>We realized that there now was a number of different node configurations/environments that required support and testing.  Furthermore we needed a way to move between these configurations quicky and seamlessly</p>

  <p>In each environment, a node broadcasts its IP/port, and the full url/path to each shard or manifest it hosts.</p>
  <ul>
    <li>If we are working in a local environment only - all nodes broadcast from 'localhost' at different TCP ports.</li>
    <li>If a node is directly on the internet, it should broadcast its own public IP and port.</li>
    <li>If a node has a fully qualified domain name, the node should broadcast that instead of a numeric IP address.</li>
    <li>If a node is behind a firewall that is configured properly for NAT translation/and port forwarding, it can still rely on its public IP and port.</li>
    <li>If a node is behind a firewall that does not have ports forwarded, it needs to either:
      <ul>
        <li>
          Establish a tunnel to Ngrok’s servers, and be aware of its unique Ngrok address so it can advertise this to other nodes,
        </li>
        <li>
          Know that it is a "Leech" node, and not broadcast location info about any files that it hosts.
        </li>
      </ul>
    </li>
  </ul>

  <p>We identified a number of configurations that a node might have, and created environment variables to represent these options.  Our node instantiation code reacts to these environment variables, and we crafted a series of BASH scripts to standardize these configurations for each environment we were working in: test, local, lan, WAN, etc.</p>

  <img src="public/images/launch_scripts.png" alt="">