<h2 id='research'>Research</h2>
  <p>As strictly end users of P2P systems, there was much research needed to understand the history and internals of these systems. We collectively read up on P2P networks, old and new: Napster, Gnutella, Freenet, BitTorrent, IPFS...</p>
 
  <h3>Understanding Decentralized Systems</h3>
  <p>The first important concept to understand is the difference between centralized and decentralized systems. A comparison of first and second generation networks helps to illustrate the difference.</p>

  <p>To talk about one of the earlier well-known P2P systems, we have to go back to the years 1999 - 2000 when Napster was very popular. Napster was a file sharing service that was mostly used to transfer music files. Itâ€™s estimated that there were about 80 million registered users at its peak.</p>

  <figure>
    <center><img src="public/images/centralized_system.png" alt="Napster centralized system"></center>
    <figcaption>An example of a centralized P2P network</figcaption>
  </figure>

  <p>Napster worked by having all nodes connect to a central index server that contained all the information about who was in possession of which files.</p>
  <p>Due to its centralized nature, Napster was vulnerable to attacks and lawsuits and Napster was shut down by court order after about 2 years of service. In addition to those vulnerabilities, the central index meant there was a single point of failure, as well as a lack of scalability.</p>

  <p>The next generation of P2P networks, such as BitTorrent, Gnutella and Freenet, are able to escape the same fate as Napster by moving to a distributed model.</p>

  <figure>
    <center><img src="public/images/distributed_system.png" alt="BitTorrent decentralized system"></center>
    <figcaption>An example of a decentralized P2P network</figcaption>
  </figure>

  <p>In a decentralized system like BitTorrent, every computer/node acts as a client and server, maintaining its own segment of a file lookup index. Nodes can find out about the locations of files through other nodes, removing the reliance on a central server.</p>

  <h3>Focusing on P2P File Sharing Systems</h3>
  <p>Knowing the advantages of newer P2P systems, we went down the path of investigating their features more deeply. Luckily P2P networks have been around for a while so there were many resources available. White papers about distributed hash tables (DHTs) proved to be the most critical, as DHTs are the foundation of current P2P networks. Countless hours were spent reading and digesting these white papers and we made sure to have a good understanding of DHTs before we started any coding.</p>
   
  <p>In addition to white papers, we relied on specification documents, various blog posts and StackOverflow answers.</p>

  <p><a href="resources/">Check out our resources section</a> if you would like to see the information uncovered while doing research.</p>
<!-- 
  [NOT SURE WHERE REMOTE TEAM SECTION GOES]
  <h3>Working with a Remote Team</h3>
  <p>Another challenge we had to overcome was a geographic one. Our team of three spanned across three time zones, with the greatest difference being 15 hours. We dedicated a significant amount of time to meet and do pair (or triple) programming.</p> -->