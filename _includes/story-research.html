<h2>Research Phase</h2>
  <p>As strictly end users of P2P systems like BitTorrent, there was a lot of research needed to understand what was going on under the hood of these systems. This phase started by reading about old and current P2P networks like Napster, Gnutella, Freenet and BitTorrent.</p>
 
  <h3>Understanding Decentralized Systems</h3>
  <p>The first important concept to understand is the difference between centralized and decentralized systems. A comparison before first and second generation helps to illustrate the difference.</p>

  <p>To talk about one of the earlier well-known P2P systems, we have to go back to the years 1999 - 2000 when Napster was very popular. For those of you who haven’t heard of it, Napster was a file sharing service that was mostly used to transfer music files. It’s estimated that there were about 80 million registered users at its peak.</p>
  <img src="public/images/centralized_system.png" alt="Napster centralized system">
  <p>Napster worked by having all nodes connect to a central index server that contained all the information about who was in possession of which files.</p>
  <p>Due to its centralized nature, Napster was vulnerable to attacks and lawsuits and Napster was shut down by court order after about 2 years of service. In addition to those vulnerabilities, the central index meant there was a single point of failure, as well as a lack of scalability.</p>

  <p>The next generation of P2P networks, such as BitTorrent, Gnutella and Freenet, are able to escape the same fate as Napster by moving to a distributed model.</p>
  <img src="public/images/distributed_system.png" alt="BitTorrent decentralized system">
  <p>In a decentralized system like BitTorrent, every computer or as we call it, node, acts as a client and server. Nodes can find out about the locations of files through other nodes, removing the reliance on a central server.</p>

  <h3>Focusing on P2P File Sharing Systems</h3>
  <p>Knowing the advantages of newer P2P systems, we went down the path of investigating their features more deeply. Luckily P2P networks have been around for a while so there were many resources available. White papers about distributed hash tables (DHTs) proved to be the most critical, as DHTs are the foundation of current P2P networks. Countless hours were spent reading and digesting these white papers and we made sure to have a good understanding of DHTs before we started any coding.</p>
   
  <p>In addition to white papers, we relied on specification documents, various blog posts and StackOverflow answers.</p>

  <p><a href="resources/">Check out our resources section</a> if you would like to see the information uncovered while doing research.</p>


  <h3>Working with a Remote Team</h3>
  <p>Another challenge we had to overcome was a geographic one. Our team of three spanned across three time zones, with the greatest difference being 15 hours. We dedicated a significant amount of time to meet and do pair (or triple) programming.</p>